### Домашнее задание 6
*Чем лучше бустить? Тестируем алгоритмы бустинга в бою.*

апр'24
<hr>

### Структура каталога

```
hw_06
├── AB_NYC_2019.csv                     - данные
├── homework_06.ipynb                   - файл с домашней работой
├── Normal_distribution_and_scales.gif  - иллюстрация 3-х сигм и прочего
└── _work                               - Рабочая папка с материалами /оставлена для своих задач автора/
```
<hr>

**Цель** :
В этом проекте вы потренируетесь строить интерпретируемые модели линейной регрессии с регуляризацией и без, а также придумывать новые признаки для
улучшения качества модели.


#### Описание/Пошаговая инструкция выполнения домашнего задания:
**Часть 1. EDA**

- Скачайте [данные](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data) с Kaggle по ценам на жильё в Airbnb в Нью-Йорке:
- Пройдите по основным шагам работы с данными:
  - выкиньте ненужные признаки: id, name, host_id, host_name, last_review 
  - визуализируйте базовые статистики данных: распределения признаков, матрицу попарных корреляций, постройте pair plots
  - про результатам анализа произведите предобработку переменных

**Часть 2. Preprocessing & Feature Engineering**

Ваша цель получить как можно более высокие метрики качества (можно взять несколько, R2, MAE, RMSE), сконцентрировавшись на преобразовании признаков.
Опробуйте различные техники:
- работа с категориальными переменными (можно начать с dummy);
- замена аномалий;
- различные варианты шкалирования непрерывных переменных (StandardScaler, RobustScaler, и.т.д.); 
- обратите внимание на распределение целевой переменной, возможно, с ней тоже можно поработать;
Попробуйте на основании имеющихся переменных создать новые, которые могли бы улучшить качество модели. Например, можно найти координаты Манхэттена (самого дорогого района) и при помощи широты и долготы, а также евклидового расстояния создать новую переменную - расстояние от квартиры до этого района. Возможно, такой признак будет работать лучше, чем просто широта и долгота.

**Часть 3. Моделирование**

- Отложите 30% данных для тестирования.
- Постройте модели простой линейной регрессии, RidgeCV, LassoCV и ElasticNetCV.
- Измерьте качество каждой и визуализируйте важность признаков.
- Сделайте интересные выводы :)

В ноутбуке желательно видеть:
- Понятное описание: какие техники и алгоритмы были опробованы - было бы неплохо в самом начале тезисно выписать опробованные методики и их результат (помогло / не помогло).
- Наличие визуализаций (не обязательно строить много графиков - можно несколько репрезентативных).
- Наличие хотя бы одной модификации данных, приводящей к улучшению результатов.

<hr>

**Критерии оценки:**

Домашнее задание принимается, если выполнены следующие действия:

- Базовая предобработка и построенные модели с оценкой качества.
- Дополнительная генерация признаков и проверка качества моделей с ними.







Цель:
В этом домашнем задании вам предстоит провести детективную работу и узнать, какой же алгоритм бустинга работает лучше всего (конечно, применительно к конкретной задаче).


Описание/Пошаговая инструкция выполнения домашнего задания:
Часть 1. EDA

Выберите любой интересующий вас датасет по классификации или регрессии (можно взять из репозитория https://archive.ics.uci.edu/ml/datasets.php, еще неплохие и востребованные на практике варианты - предсказание оттока пользователей https://www.kaggle.com/blastchar/telco-customer-churn или предсказание Customer Livetime Value (CLV или LTV) - https://www.kaggle.com/pankajjsh06/ibm-watson-marketing-customer-value-data
По выбранному датасету проведите EDA, познакомьтесь с признаками, посмотрите зависимости и т.д.
Часть 2. Preprocessing & Feature Engineering
Хотя цель этого задания - посмотреть на работу алгоритмов, тем не менее пропускать препроцессинг нельзя :)
Так что переведите категориальные переменные в уникальные лейблы при помощи LabelEncoder, попробуйте добавить новые переменные и выкинуть лишние и, наконец, разбейте данные на train-test.
Часть 3. Who's the mightiest of them all?
Постройте 4 варианта градиентного бустинга, используя значения гиперпараметров “из коробки”: реализация из sklearn, XGBoost, CatBoost, LightGBM
Проверьте качество на отложенной выборке, кто пока лидирует?
Теперь проведите настройку гиперпараметров моделей на кросс-валидации, можно настраивать только самые основные гиперпараметры - число итераций бустинга, max_features, subsample и т.д.
Снова проверьте качество уже настроенных моделей. Кто в итоге победил?

Критерии оценки:
EDA для выбранного датасета - 1 балл.
Preprocessing - 1 балл.
Построение моделей из коробки и проверка качества - 4 балла.
Настройка гиперпараметров моделей и проверка качества - 4 балла.